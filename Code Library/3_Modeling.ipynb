{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Modeling \n",
    "\n",
    "_For USD-599 Capstone Project by Hunter Blum, Kyle Esteban Dalope, and Nicholas Lee (Summer 2023)_\n",
    "\n",
    "***\n",
    "\n",
    "**Content Overview:**\n",
    "1. Pipeline Creation\n",
    "2. Data Splitting - Split by property_type_binary and train test split for each\n",
    "3. Modeling - Two sets of models based on propery_type_binary that will be evaluated separately\n",
    "4. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.pipeline import make_pipeline, Pipeline \n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import set_config\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn import linear_model\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data from the previous notebook\n",
    "clean_data = pd.read_csv(\"../Data/model_ready.csv.gz\", compression = \"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "host_listings_count                             float64\n",
       "property_type                                    object\n",
       "room_type                                        object\n",
       "bathrooms                                       float64\n",
       "bedrooms                                        float64\n",
       "price                                           float64\n",
       "minimum_nights                                    int64\n",
       "maximum_nights                                    int64\n",
       "minimum_minimum_nights                          float64\n",
       "maximum_maximum_nights                          float64\n",
       "has_availability                                 object\n",
       "availability_30                                   int64\n",
       "availability_365                                  int64\n",
       "instant_bookable                                 object\n",
       "calculated_host_listings_count                    int64\n",
       "calculated_host_listings_count_private_rooms      int64\n",
       "calculated_host_listings_count_shared_rooms       int64\n",
       "reviews_per_month                               float64\n",
       "zipcode                                           int64\n",
       "median_income_dollars                           float64\n",
       "property_type_binary                             object\n",
       "private                                           int64\n",
       "sentiment                                       float64\n",
       "review_score_weighted                           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change some features to the proper data types\n",
    "# i.e. zipcode to categorical\n",
    "clean_data[\"zipcode\"] = clean_data[\"zipcode\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do we need to drop _property_type_ and _room_type_?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data by property type\n",
    "\n",
    "house_df = clean_data.loc[clean_data[\"property_type_binary\"] == \"house\"]\n",
    "room_df = clean_data.loc[clean_data[\"property_type_binary\"] == \"room\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Setup\n",
    "-  Establish a unique pipeline for numerical and categorical columns separately\n",
    "- Partition the dataset into training and test set (75:25 split)\n",
    "- Fit and apply the transformer to the training set\n",
    "- Applied the trained transformer to the test set\n",
    "- Return the preprocessed, model-ready training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Maybe we go back and keep _review_scores_average_ and in the pipeline, multiple the two features (avg. score and # of monthly reviews) together, to create a weighted score, and then drop it?**\n",
    "\n",
    "I'm thinking if this app is for users, they will have this information will be readily accessible and they can enter it themselves. If we take this approach, we'll need to keep the original features so the vector exists for them in the model training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numerical and categorical features\n",
    "num_cols = clean_data.select_dtypes([\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_cols = clean_data.select_dtypes(\"object\").columns.tolist()\n",
    "\n",
    "# Separate out the target\n",
    "num_cols.remove('price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Should we add an imputer to the numerical data in the event that a user decides to leave a field empty, downstream?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up separate pipelines for different datatypes\n",
    "\n",
    "# Set transformer output as a pandas dataframe\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "# Numerical Pipeline\n",
    "num_pipeline = Pipeline([\n",
    "    (\"standardscaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical Pipeline\n",
    "categorical_pipeline = Pipeline([\n",
    "    # Handle_unknown = \"ignore\" to deal with one off values in categorical features\n",
    "    (\"encoder\", OneHotEncoder(\n",
    "        sparse_output = False, drop = \"if_binary\", handle_unknown = \"ignore\"\n",
    "        )\n",
    "    )\n",
    "])\n",
    "\n",
    "# Global Data Pipeline\n",
    "data_transformer = ColumnTransformer(\n",
    "    transformers = [\n",
    "        (\"numerical\", num_pipeline, num_cols),\n",
    "        (\"categorical\", categorical_pipeline, categorical_cols)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to output preprocessed, model-ready data using the data_transformer\n",
    "def preprocess_data(data_set, pipeline = data_transformer,\n",
    "                    num_cols = num_cols, categorical_cols = categorical_cols):\n",
    "    \n",
    "    # Data partitioning 75:25 Train-Test Split\n",
    "    training_data, testing_data = train_test_split(\n",
    "        data_set, test_size = 0.25, random_state = 2023\n",
    "        )\n",
    "    \n",
    "    # Separate target from df\n",
    "    training_data_X = training_data.drop(columns = ['price'])\n",
    "    train_data_y = training_data['price']\n",
    "\n",
    "    testing_data_X = testing_data.drop(columns = ['price'])\n",
    "    test_data_y = testing_data['price']\n",
    "\n",
    "    # Fit and transform the training data partition\n",
    "    train_data_X = pipeline.fit_transform(training_data_X)        \n",
    "\n",
    "    # Transform the test data set based on the training data\n",
    "    test_data_X = pipeline.transform(testing_data_X)\n",
    "\n",
    "    # Remove whitespace in col names\n",
    "    train_data_X.columns = train_data_X.columns.str.replace(' ', '_')\n",
    "    test_data_X.columns = test_data_X.columns.str.replace(' ', '_')\n",
    "\n",
    "    # Remove slashes in col names\n",
    "    train_data_X.columns = train_data_X.columns.str.replace('/', '_')\n",
    "    test_data_X.columns = test_data_X.columns.str.replace('/', '_')\n",
    "\n",
    "    return train_data_X, train_data_y, test_data_X, test_data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HunterBlum\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\preprocessing\\_encoders.py:227: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "C:\\Users\\HunterBlum\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\preprocessing\\_encoders.py:227: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the house-type and room-type data sets\n",
    "house_train_X, house_train_y, house_test_X, house_test_y = preprocess_data(house_df)\n",
    "room_train_X, room_train_y, room_test_X, room_test_y = preprocess_data(room_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model - Backwards Stepwise Regression\n",
    "\n",
    "Since we do not have too many training features, it will be better to use backwards stepwise regression to test all of our features. \n",
    "\n",
    "### Entire House Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Room Model\n",
    "First we'll do backward selection with sklearn, then we'll the final model with statsmodels for improved diagnostic tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the sklearn backward selected model\n",
    "room_back_reg = SequentialFeatureSelector(linear_model.LinearRegression(),\n",
    "                                          n_features_to_select = 'auto',\n",
    "                                          direction='backward',\n",
    "                                          n_jobs = -1).fit(room_train_X, room_train_y)\n",
    "\n",
    "room_train_X_back = room_back_reg.transform(room_train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.208\n",
      "Model:                            OLS   Adj. R-squared:                  0.197\n",
      "Method:                 Least Squares   F-statistic:                     20.16\n",
      "Date:                Wed, 26 Jul 2023   Prob (F-statistic):          4.59e-101\n",
      "Time:                        12:49:47   Log-Likelihood:                -18212.\n",
      "No. Observations:                2493   AIC:                         3.649e+04\n",
      "Df Residuals:                    2460   BIC:                         3.668e+04\n",
      "Df Model:                          32                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================================================================\n",
      "                                                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                                     -1.251e+13    1.6e+15     -0.008      0.994   -3.16e+15    3.13e+15\n",
      "numerical__host_listings_count                                    8.2863      7.925      1.046      0.296      -7.253      23.826\n",
      "numerical__bathrooms                                             23.6646      8.075      2.930      0.003       7.829      39.500\n",
      "numerical__bedrooms                                              64.1483      8.310      7.719      0.000      47.852      80.444\n",
      "numerical__maximum_maximum_nights                               -13.8253      7.476     -1.849      0.065     -28.485       0.835\n",
      "numerical__availability_365                                     -29.5023      7.622     -3.871      0.000     -44.448     -14.557\n",
      "numerical__reviews_per_month                                    -35.0854      9.963     -3.522      0.000     -54.622     -15.549\n",
      "numerical__median_income_dollars                                 10.6450      7.427      1.433      0.152      -3.920      25.210\n",
      "numerical__private                                              -78.4369     14.888     -5.268      0.000    -107.631     -49.242\n",
      "numerical__sentiment                                             15.6402      7.382      2.119      0.034       1.165      30.116\n",
      "numerical__review_score_weighted                                  9.0990      9.828      0.926      0.355     -10.173      28.371\n",
      "categorical__property_type_Private_room_in_bed_and_breakfast    915.7058     62.982     14.539      0.000     792.204    1039.208\n",
      "categorical__property_type_Private_room_in_boat                  57.4292    256.730      0.224      0.823    -446.000     560.858\n",
      "categorical__property_type_Private_room_in_castle               -39.6740    362.853     -0.109      0.913    -751.204     671.856\n",
      "categorical__property_type_Private_room_in_cave                 -16.3835    362.974     -0.045      0.964    -728.150     695.383\n",
      "categorical__property_type_Private_room_in_condo                -21.9705     26.215     -0.838      0.402     -73.376      29.435\n",
      "categorical__property_type_Private_room_in_cottage              -25.0103    105.793     -0.236      0.813    -232.462     182.442\n",
      "categorical__property_type_Private_room_in_dome                 -10.3523    256.720     -0.040      0.968    -513.761     493.056\n",
      "categorical__property_type_Private_room_in_earthen_home         -50.6410    362.626     -0.140      0.889    -761.724     660.442\n",
      "categorical__property_type_Private_room_in_farm_stay             75.0851    362.782      0.207      0.836    -636.305     786.475\n",
      "categorical__property_type_Private_room_in_hut                  -76.4921    256.538     -0.298      0.766    -579.545     426.560\n",
      "categorical__property_type_Private_room_in_resort               174.7180     71.927      2.429      0.015      33.674     315.762\n",
      "categorical__property_type_Private_room_in_serviced_apartment    30.9572    101.624      0.305      0.761    -168.321     230.235\n",
      "categorical__property_type_Private_room_in_tent                 -94.7034    256.576     -0.369      0.712    -597.831     408.424\n",
      "categorical__property_type_Room_in_hotel                        122.0777     50.125      2.435      0.015      23.787     220.369\n",
      "categorical__property_type_Shared_room_in_bed_and_breakfast     205.5741    263.347      0.781      0.435    -310.831     721.979\n",
      "categorical__property_type_Shared_room_in_boutique_hotel        -18.9350    367.736     -0.051      0.959    -740.039     702.169\n",
      "categorical__property_type_Shared_room_in_hostel                -84.3941     88.911     -0.949      0.343    -258.743      89.955\n",
      "categorical__property_type_Shared_room_in_hotel                 284.3567    367.651      0.773      0.439    -436.581    1005.294\n",
      "categorical__property_type_Shared_room_in_loft                  -70.8547    217.743     -0.325      0.745    -497.833     356.123\n",
      "categorical__property_type_Shared_room_in_rental_unit           -89.9801     99.546     -0.904      0.366    -285.182     105.222\n",
      "categorical__property_type_Shared_room_in_tiny_home             -28.5668    367.536     -0.078      0.938    -749.279     692.146\n",
      "categorical__room_type_Private_room                             197.0837     70.171      2.809      0.005      59.484     334.683\n",
      "categorical__property_type_binary_room                         1.251e+13    1.6e+15      0.008      0.994   -3.13e+15    3.16e+15\n",
      "==============================================================================\n",
      "Omnibus:                     4840.443   Durbin-Watson:                   2.017\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         11172057.724\n",
      "Skew:                          14.891   Prob(JB):                         0.00\n",
      "Kurtosis:                     329.598   Cond. No.                     5.37e+14\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 2.55e-26. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "# Combine the dataframe back into one for the model\n",
    "room_train_back = pd.concat([room_train_X_back, room_train_y], axis = 1)\n",
    "\n",
    "# Get string of columns for formula\n",
    "cols = list(room_train_X_back.columns)\n",
    "cols_str = \" + \".join(cols)\n",
    "cols_str = str(cols_str)\n",
    "\n",
    "# Fit the model\n",
    "room_back_reg_fin = smf.ols(formula= 'price ~' + cols_str, \n",
    "                            data = room_train_back).fit()\n",
    "\n",
    "# Model summary\n",
    "print(room_back_reg_fin.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residuals vs. Fitted Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16749     -2.435547\n",
       "6568     238.208984\n",
       "6135      -6.466797\n",
       "16098    -67.335938\n",
       "7457    -344.105469\n",
       "            ...    \n",
       "12956    -69.892578\n",
       "16506     -9.441406\n",
       "15788   -235.166016\n",
       "11420    -41.162109\n",
       "6822       2.517578\n",
       "Length: 2493, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals = room_back_reg_fin.resid\n",
    "fitted = room_back_reg_fin.fittedvalues\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
